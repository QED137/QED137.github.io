<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Statistics Blog</title>
    <link rel="stylesheet" href="statistics.css">
</head>
<body>

    <!-- Navbar -->
    <header class="navbar">
        <h1>Statistics & Data Science</h1>
        <nav>
            <a href="../index.html">Home</a>
            <a href="blogs.html" class="active">Blogs</a>
            <!-- <a href="statistics.html" class="active">Statistics</a>
            <a href="physics.html">Physics</a>
            <a href="mathematics.html">Mathematics</a>
            <a href="machinelearning.html">Machine Learning</a> -->
            
            <a href="../about/about.html">About</a>
        </nav>
    </header>
    
    <!-- Hero Section -->
    <!-- <section class="hero">
        <h2>Unraveling Insights from Data</h2>
        <p>Explore statistical methods, probability theories, and real-world data applications.</p>
    </section> -->
    <section class="blog-header">
        <div class="container">
            <h1>Automating Real-Time Data Pipelines: Integrating Weather and Flight APIs with Python andÂ MySQL</h1>
            <p>Learn how to build a real-time data pipeline using Python to fetch weather and flight information and store it in a MySQL database.</p>  
            <p>By <strong>Janmajay Kumar</strong> | October 2024</p>
        </div>
    </section>

    <section class="blog-content">
        <div class="container">
            <h2>Introduction</h2>
            <p>Real-time data processing is a critical component in modern applications, enabling businesses to gain insights and react instantly to new information. This blog explores how to automate a real-time data pipeline using **Google Cloud Platform (GCP)**.</p>

            <h2>1. Architecture Overview</h2>
            <p>The real-time data pipeline consists of:</p>
            <ul>
                <li><strong>Google Pub/Sub</strong> - Event ingestion & messaging</li>
                <li><strong>Cloud Dataflow</strong> - Stream processing & transformations</li>
                <li><strong>BigQuery</strong> - Data storage & analytics</li>
                <li><strong>Cloud Functions</strong> - Event-driven triggers</li>
            </ul>
            <img src="../images/google-cloud-architecture.png" alt="Google Cloud Architecture">

            <h2>2. Setting Up Pub/Sub for Data Streaming</h2>
            <p>Google Pub/Sub acts as a messaging service, allowing multiple sources to publish data, which is then processed downstream.</p>
            <pre><code>
gcloud pubsub topics create my-topic
gcloud pubsub subscriptions create my-subscription --topic=my-topic
            </code></pre>

            <h2>3. Processing Data Using Cloud Dataflow</h2>
            <p>Google Cloud Dataflow, powered by Apache Beam, is used for stream processing.</p>
            <pre><code>
python my_dataflow_pipeline.py --runner=DataflowRunner --project=my-project
            </code></pre>

            <h2>4. Storing Data in BigQuery</h2>
            <p>Processed data is stored in BigQuery for analytics.</p>
            <pre><code>
bq query --use_legacy_sql=false 'SELECT * FROM my_dataset.realtime_data'
            </code></pre>

            <h2>5. Automating with Cloud Functions</h2>
            <p>Google Cloud Functions automate the pipeline by triggering actions when new data arrives.</p>
            <pre><code>
gcloud functions deploy my-function --trigger-topic=my-topic
            </code></pre>

            <h2>Conclusion</h2>
            <p>By integrating these GCP services, we create a scalable, automated, and real-time data pipeline. This architecture is ideal for applications requiring instant data processing and analytics.</p>
        </div>
    </section>

    <footer>
        <p>&copy; 2025 Data Engineering Blog | Created by Janmajay Kumar</p>
    </footer>

</body>
</html>